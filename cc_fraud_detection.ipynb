{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dab08d",
   "metadata": {},
   "source": [
    "### Consider:\n",
    "* Use isfraud as target for target encoding\n",
    "* Do not use one-hot encoding\n",
    "* Refactor preprocessing functions to work with sklearn.pipeline.pipeline\n",
    "* Use sklearn.model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kagglehub import dataset_load, KaggleDatasetAdapter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    'ealtman2019/credit-card-transactions',\n",
    "    'credit_card_transactions-ibm_v2.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_col_names(col: str) -> str:\n",
    "    # Lowercase all characters and remove non-alphabetics\n",
    "    return ''.join(char.lower() for char in col if char.isalpha())\n",
    "\n",
    "\n",
    "def clean_data(transactions: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Rename columns\n",
    "    col_names = {col: format_col_names(col) for col in transactions.columns}\n",
    "    transactions = transactions.rename(columns = col_names)\n",
    "\n",
    "    # Parse hour and minute data from time column\n",
    "    transactions['hour'] = transactions['time'].str[0:2].astype('int64')\n",
    "    transactions['minute'] = transactions['time'].str[3:5].astype('int64')\n",
    "\n",
    "    # Convert amount to float\n",
    "    transactions['amount'] = transactions['amount'].str.replace('$', '').astype('float')\n",
    "\n",
    "    # Convert isfraud to binary\n",
    "    transactions['isfraud'] = transactions['isfraud'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "    # Log transform amount to yield a less skewed distribution\n",
    "    transactions['logamount'] = np.log(transactions['amount'])\n",
    "    transactions['logamount'] = transactions['logamount'].fillna(0)\n",
    "    transactions.loc[transactions['logamount'] == -np.inf, ['logamount']] = 0\n",
    "\n",
    "    drop_cols = ['user', 'card', 'time', 'amount']\n",
    "\n",
    "    return transactions.drop(columns = drop_cols)\n",
    "\n",
    "\n",
    "def encode_categoricals(transactions: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Encode usechip, errors\n",
    "    \n",
    "    dummies_usechip = transactions['usechip'].str.get_dummies()\n",
    "    dummies_errors = transactions['errors'].str.get_dummies(sep = ',')\n",
    "\n",
    "    drop_cols = ['usechip', 'errors']\n",
    "\n",
    "    return pd.concat([transactions.drop(columns = drop_cols), dummies_usechip, dummies_errors], axis = 'columns')\n",
    "\n",
    "\n",
    "def balance_data(transactions: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Sample the data, yielding a dataset balanced on isfraud\n",
    "\n",
    "    num_fraud = transactions.loc[transactions['isfraud'] == 1].shape[0] # 29757\n",
    "    num_samples = round(0.8*num_fraud)\n",
    "\n",
    "    fraudulent = transactions.loc[transactions['isfraud'] == 1].sample(num_samples)\n",
    "    not_fraudulent = transactions.loc[transactions['isfraud'] == 0].sample(num_samples)\n",
    "\n",
    "    return pd.concat([fraudulent, not_fraudulent])\n",
    "\n",
    "\n",
    "def process_balance(transactions: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    transactions = clean_data(transactions)\n",
    "    transactions = encode_categoricals(transactions)\n",
    "    transactions = balance_data(transactions)\n",
    "\n",
    "    # Shuffle data\n",
    "    return transactions.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510375a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_processed_balanced = process_balance(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(transactions: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Target encoding for merchantcity, merchantstate, merchantname, zip, mcc\n",
    "    # To avoid data leakage, perform this function last (after balancing)\n",
    "\n",
    "    drop_cols = ['merchantname', 'merchantcity', 'merchantstate', 'zip', 'mcc']\n",
    "\n",
    "    y = transactions['logamount'].to_numpy()\n",
    "\n",
    "    for col in drop_cols:\n",
    "\n",
    "        target_encoded = TargetEncoder().fit_transform(transactions[col].to_numpy().reshape(-1, 1), y)\n",
    "        \n",
    "        transactions = pd.concat([\n",
    "            transactions.drop(columns = col),\n",
    "            pd.DataFrame(target_encoded, columns = ['target_encoded_' + f'{col}'], index = transactions.index)\n",
    "            ],\n",
    "            axis = 'columns'\n",
    "        )\n",
    "\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def cv_fit_model(\n",
    "    model,\n",
    "    transactions: pd.DataFrame,\n",
    "    n_splits: int,\n",
    "    target_col: str\n",
    ") -> tuple[list, list]:\n",
    "    \n",
    "    # Fit model with cross-validation\n",
    "\n",
    "    models = []\n",
    "    scores = []\n",
    "\n",
    "    kf = KFold(n_splits = n_splits)\n",
    "\n",
    "    for train_ind, test_ind in kf.split(transactions):\n",
    "\n",
    "        # Perform target encoding independently on each split to avoid data leakage\n",
    "        train = target_encoding(transactions.iloc[train_ind])\n",
    "        test = target_encoding(transactions.iloc[test_ind])\n",
    "\n",
    "        model.fit(train.drop(columns = [target_col]), train[target_col])\n",
    "        models.append(model)\n",
    "\n",
    "        score = model.score(test.drop(columns = [target_col]), test[target_col])\n",
    "        scores.append(score)\n",
    "\n",
    "    return (models, scores)\n",
    "\n",
    "\n",
    "def gen_confusion_matrix(\n",
    "    model_scores: tuple[list, list],\n",
    "    transactions: pd.DataFrame,\n",
    "    target_col: str\n",
    ") -> ConfusionMatrixDisplay:\n",
    "\n",
    "    # Generate a confusion matrix\n",
    "\n",
    "    median_score = st.median(model_scores[1])\n",
    "    median_ind = model_scores[1].index(median_score)\n",
    "    median_model = model_scores[0][median_ind]\n",
    "\n",
    "    return ConfusionMatrixDisplay.from_estimator(\n",
    "        median_model,\n",
    "        target_encoding(transactions.drop(columns = [target_col])),\n",
    "        transactions[target_col],\n",
    "        normalize = 'true',\n",
    "        cmap = 'Blues'\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_roc_curve(\n",
    "    model_scores: tuple[list, list],\n",
    "    transactions: pd.DataFrame,\n",
    "    target_col: str\n",
    ") -> RocCurveDisplay:\n",
    "\n",
    "    # Generate a ROC curve\n",
    "\n",
    "    median_score = st.median(model_scores[1])\n",
    "    median_ind = model_scores[1].index(median_score)\n",
    "    median_model = model_scores[0][median_ind]\n",
    "\n",
    "    return RocCurveDisplay.from_estimator(\n",
    "        median_model,\n",
    "        target_encoding(transactions.drop(columns = [target_col])),\n",
    "        transactions[target_col]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e20e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "\n",
    "logistic_model_scores = cv_fit_model(\n",
    "    LogisticRegression(solver = 'newton-cholesky'),\n",
    "    transactions_processed_balanced,\n",
    "    n_splits = 5,\n",
    "    target_col = 'isfraud'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a199edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_confusion_matrix(logistic_model_scores, transactions_processed_balanced, target_col = 'isfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352db0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_roc_curve(logistic_model_scores, transactions_processed_balanced, target_col = 'isfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97566929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram gradient boosting tree model\n",
    "\n",
    "hgb_model_scores = cv_fit_model(\n",
    "    HistGradientBoostingClassifier(validation_fraction = None),\n",
    "    transactions_processed_balanced,\n",
    "    n_splits = 5,\n",
    "    target_col = 'isfraud'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b77be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_confusion_matrix(hgb_model_scores, transactions_processed_balanced, target_col = 'isfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_roc_curve(hgb_model_scores, transactions_processed_balanced, target_col = 'isfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41102b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
